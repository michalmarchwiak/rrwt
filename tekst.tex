\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{polski}

\title{rr}
\author{Mirek Myszka}
\date{December 2024}

\begin{document}

\maketitle

\section*{Dynamika zawodników defensywnych podczas meczu piłki nożnej. Optymalizacja ustawienia} 

Odkąd w Cambridge w 1848 roku zapisano pierwsze zasady piłki nożnej, gra nieustannie ewoluuje. Początkowo najpopularniejszą formacją była tak zwana „odwrócona piramida”, czyli ustawienie 1-2-3-5. Dopiero później uświadomiono sobie, że dwóch środkowych obrońców to zdecydowanie za mało, i dziś w formacji obronnej widujemy trzech, czterech, a nawet pięciu obrońców. Jeden z najlepszych menedżerów w piłce nożnej, Sir Alex Ferguson, powiedział: „Atak wygrywa ci mecze, obrona wygrywa ci trofea” – i jest w tym wiele prawdy. Aby wygrać mecz, zazwyczaj musisz zdobyć jedną bramkę więcej niż przeciwnik, a staje się to o wiele łatwiejsze, gdy twoja defensywa jest szczelna.

Na zachowanie obrońcy wpływa wiele czynników, ale my skupimy się głównie na trzech z nich: wyznaczonej pozycji, odległości od przeciwnika oraz odległości od kolegów z drużyny. W naszym projekcie postaramy się znaleźć optymalne zachowanie obrońców za pomocą równania różniczkowego i zdecydować, jaka mieszanka tych czynników przynosi najlepsze rezultaty w obronie własnej bramki. Oczywiście tak uproszczony model nie rozwiąże problemów menedżerów największych klubów piłkarskich, ale może okazać się pomocny przy planowaniu treningów czy tworzeniu piłkarskich gier komputerowych.

\section*{Wzór na całkowitą siłę działającą na zawodnika}

Równanie opisujące całkowitą siłę działającą na $i$-tego zawodnika w drużynie można zapisać jako:

\begin{equation}
    \frac{d \textbf{r}_{i}}{dt}=\textbf{F}_{pos,i}+\textbf{F}_{opp,i}+\textbf{F}_{team,i}
\end{equation}

Gdzie:
\begin{itemize}
    \item \(\mathbf{r}_i(t)\): Pozycja \(i\)-tego obrońcy w czasie \(t\) jako wektor \([\mathbf{x}_i(t), \mathbf{y}_i(t)]\).
    \item \(\frac{d\mathbf{r}_i}{dt}\): Prędkość \(i\)-tego obrońcy (zmiana pozycji w czasie).
    \item \(\mathbf{F}_{\text{pos},i}\): Siła przyciągania \(i\)-tego obrońcy do ustalonej pozycji na boisku
    \item \(\mathbf{F}_{\text{opp},i}\): Siła działająca na \(i\)-tego obrońce reagująca na przeciwnika z piłką
    \item \(\mathbf{F}_{\text{team},i}\): Siła działająca na \(i\)-tego obrońce reagująca na pozycje kolegów z drużyny
\end{itemize}
Zgodnie z \textbf{zasadą superpozycji} w mechanice klasycznej, siły pochodzące z różnych źródeł mogą być sumowane w celu wyznaczenia całkowitej siły działającej na ciało.

\subsection*{1. Siła dążenia do pozycji (\(F_{\text{pos}, i}\))}

Siła ta opisuje dążenie zawodnika do swojej wyznaczonej pozycji na boisku. Bazuje ona na \textbf{prawie Hooke’a} (siła sprężystości): \(F = -k \cdot x\).
\[
F_{\text{pos}, i} = -k_{\text{pos}} \cdot (r_i - r_{\text{pos}, i})
\]
\begin{itemize}
    \item \(r_i\) - aktualna pozycja \(i\)-tego zawodnika,
    \item \(r_{\text{pos}, i}\) - wyznaczona pozycja \(i\)-tego zawodnika,
    \item \(k_{\text{pos}}\) - współczynnik określający intensywność dążenia do celu.
\end{itemize}

\subsection*{2. Siła przyciągania do przeciwnika (\(F_{\text{opp}, i}\))}

Siła ta opisuje reakcję zawodnika na pozycję przeciwnika. Bazuje ona na \textbf{prawie grawitacji} (przyciąganie ciał)
\[
F_{\text{opp}, i} = \frac{k_{\text{opp}} \cdot (r_{\text{opp}} - r_i)}{\|r_{\text{opp}} - r_i\|^2 + \epsilon}
\]
\begin{itemize}
    \item \(r_{\text{opp}}\) - pozycja przeciwnika z piłką,
    \item \(r_i\) - aktualna pozycja \(i\)-tego zawodnika,
    \item \(k_{\text{opp}}\) - współczynnik określający intensywność reakcji na przeciwnika,
    \item \(\epsilon\) - mała wartość dodana w celu uniknięcia dzielenia przez zero.
\end{itemize}
W naszym modelu zawodnik $i$ jest przyciągany przez przeciwnika w punkcie $\mathbf{r}_{\text{opp}}$, a siła maleje z kwadratem odległości ($\|\mathbf{r}_{\text{opp}} - \mathbf{r}_i\|^2$). Współczynnik $k_{\text{opp}}$ kontroluje, jak silne jest przyciąganie, a $\varepsilon$ zapobiega dzieleniu przez zero, gdy zawodnik $i$ znajduje się bardzo blisko przeciwnika.

\subsection*{3. Siła odpychania od kolegów z drużyny (\(F_{\text{team}, i}\))}

Siła ta opisuje interakcje przestrzenne zawodnika z innymi członkami drużyny. Bazuje ona na \textbf{prawie Coulomba} (odpychanie między ładunkami): \(F \sim \frac{1}{r^2}\).
\[
F_{\text{team}, i} = \sum_{j \neq i} \frac{-k_{\text{team}} \cdot (r_j - r_i)}{\|r_j - r_i\|^2 + \epsilon}
\]
\begin{itemize}
    \item \(r_j\) - pozycja \(j\)-tego kolegi z drużyny,
    \item \(r_i\) - aktualna pozycja \(i\)-tego zawodnika,
    \item \(k_{\text{team}}\) - współczynnik określający intensywność odpychania,
    \item \(\epsilon\) - mała wartość dodana w celu uniknięcia dzielenia przez zero.
\end{itemize}
Ten składnik inspirowany jest zjawiskiem "odpychania", podobnym do sił między naładowanymi cząstkami w modelu elektrostatycznym, gdzie zawodnicy unikają nadmiernego tłoku wokół siebie.

\subsection*{Podobieństwo do algorytmu stada \textbf{(Boids)}}
Stworzony przez nas wzór jest bardzo podobny do algorytmu \textit{Boids}, opracowanego przez Craiga Reynoldsa w 1986 roku, który służy do symulowania zachowań grupy autonomicznych agentów (np. ptaków, ryb, owadów) poruszających się w przestrzeni na podstawie trzech prostych zasad: separacji, wyrównania i kohezji. Zasady te w pewnym sensie odpowiadają naszym zasadom ruchu.

\begin{itemize}
    \item \textbf{Separacja} w \textit{Boids} zapobiega zderzeniom między agentami, co w naszym przypadku odpowiada sile \( F_{\text{team}, i} \), która utrzymuje odpowiednią odległość między obrońcami, zapobiegając zbytnim skupiskom.  
    \item \textbf{Wyrównanie} powoduje, że boidy dążą do wyrównania swoich prędkości, ten aspekt nie ma odzwierciedlenia w naszym modelu.  
    \item \textbf{Kohezja} zapewnia spójność grupy, co w naszym modelu odpowiada równowadze między siłami \( F_{\text{goal}, i} \) i \( F_{\text{opp}, i} \), które pomagają obrońcom reagować na ruchy przeciwnika, jednocześnie utrzymując pozycje w drużynie.
\end{itemize}

\section*{Symulacja ataku na bramkę}
Korzystając z naszego wzoru przygotowaliśmy prostą symulacje obrony akcji bramkowej. Napastnicy przemieszczają się w linii prostej w stronę pola karnego, a zachowanie obrońców jest wynikową sumy naszych sił działających na nich. Gdy dochodzi do spotkania defensora i atakującego z piłką z prawdopodobieństwem 50 procent albo piłka zostaje odebrana co kończy symulacje na korzyść drużyny broniącej, albo z takim samym prawdopodobieństwem napastnik podaje piłkę do najbliższego kolegi z kolegi z drużyny który jest w bezpiecznej pozycji. Zwycięstwem druzyny atakującej jest dotarcie do pola karnego przeciwnika.

\section*{Optymalizacja}

Chcemy znaleźć takie wartości parametrów \(k_{\text{pos}}, k_{\text{opp}}, k_{\text{team}}\), które maksymalizują funkcję celu:
\[
f(k_{\text{pos}}, k_{\text{opp}}, k_{\text{team}}) = \frac{1}{N} \sum_{i=1}^N \text{simulate}(k_{\text{pos}}, k_{\text{opp}}, k_{\text{team}})
\]
gdzie \(\text{simulate}\) zwraca wynik pojedynczej symulacji (1 dla sukcesu obrońców, 0 dla porażki), a N oznacza liczbę przeprowadzonych symulacji (w naszym przypadku będzie to 100). W tym celu zastosujemy metodę \textit{gradient ascent}, aby iteracyjnie znaleźć maksimum tej funkcji.

\section*{Implementacja metody gradient ascent}

Gradient ascent to iteracyjna metoda znajdowania maksimum funkcji. W odróżnieniu od gradient descent, w którym schodzimy w dół funkcji, w gradient ascent poruszamy się w kierunku gradientu, czyli w górę funkcji poszukując jej maksimum.

\subsection*{Gradient funkcji celu}

\[
\nabla f = \left( \frac{\partial f}{\partial k_{\text{pos}}}, \frac{\partial f}{\partial k_{\text{opp}}}, \frac{\partial f}{\partial k_{\text{team}}} \right)
\]

Ponieważ \(f\) nie jest podana w sposób analityczny, gradient liczymy numerycznie:
\[
\frac{\partial f}{\partial k_i} \approx \frac{f(k + \epsilon e_i) - f(k - \epsilon e_i)}{\epsilon}
\]
gdzie \(e_i\) to jednostkowy wektor wskazujący kierunek parametru \(\omega_i\), a \(\epsilon\) to mała wartość, np. \(10^{-6}\).

\subsection*{Aktualizacja parametrów}
W gradient ascent aktualizujemy parametry, poruszając się w kierunku gradientu:
\[
k^{(t+1)} = k^{(t)} + \alpha \nabla f(k^{(t)})
\]
gdzie:
\begin{itemize}
    \item \(k^{(t)}\): Wektor parametrów w iteracji \(t\).
    \item \(\alpha\): Krok uczenia (\textit{learning rate}) — mała wartość decydująca o wielkości kroku w kierunku gradientu. Dzięki jego odpowiedniego dobraniu możemy uniknąć zbieżności do maksimum lokalnego i zamiast tego zmierzać w kierunku maksimum globalnego.
    \item \(\nabla f(k^{(t)})\): Gradient funkcji celu w bieżącym punkcie.
\end{itemize}

\subsection*{3. Kroki algorytmu}
\begin{enumerate}
    \item \textbf{Inicjacja parametrów:} Wybieramy początkowe wartości \(k_{\text{pos}}, k_{\text{opp}}, k_{\text{team}}\). W naszym przypadku (5.0, 5.0, 5.0)
    \item \textbf{Liczenie gradientu:} Wyznaczamy gradient \(\nabla f\) numerycznie w bieżącym punkcie.
    \item \textbf{Aktualizacja parametrów:} Aktualizujemy wartości parametrów zgodnie ze wzorem aktualizacji.
    \item \textbf{Powtórz:} Powtarzamy kroki od 2 do 3 określoną liczbę razy.
\end{enumerate}
Ze względu na element losowości w naszej symulacji, funkcja nie osiągnie jednego, definitywnego maksimum. Dlatego zamiast ustalać warunek stopu, iterujemy algorytm przez dużą liczbę kroków. W praktyce, jeśli sukces obrońców wzrasta parametry są przesuwane w kierunku odpowiadającemu większemu sukcesowi.


\section*{Wynik symulacji}
chuj

\end{document}
